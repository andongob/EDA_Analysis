{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335757cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3647154",
   "metadata": {
    "cell_marker": "######################################################################################"
   },
   "source": [
    "                          TRÁFICO WEB DE RED                    \n",
    "Autor: Ana Ndongo\n",
    "Fecha: 20/10/2024   \n",
    "dataSet:  https://www.kaggle.com/datasets/rudrakumar96/web-firewall-good-and-bad-request\n",
    "Variable objetivo: class\n",
    "          \n",
    "#####################################################################################\n",
    " Sobre el Conjunto de Datos\n",
    " Este conjunto de datos contiene registros de tráfico de red capturados con \n",
    " Burp-Suite, orientados a clasificar las solicitudes web como buenas o malas \n",
    " según sus características. El conjunto de datos está diseñado para la tarea de \n",
    " predecir si las solicitudes entrantes son legítimas (buenas) o maliciosas (malas), \n",
    " ayudando en la detección y prevención de ataques basados en la web.\n",
    "\n",
    " --- Resumen de los pasos realizados ---\n",
    "\n",
    "1. Cargar el archivo CSV original.\n",
    "2. Eliminar columnas irrelevantes.\n",
    "3. Imputar valores nulos en body con \"EMPTY\".\n",
    "4. Crear nuevas columnas con recuentos de palabras clave sospechosas.\n",
    "5. Análisis exploratorio# \n",
    "6. Identificar outliers con boxplots.\n",
    "7. Calcular correlaciones con la variable objetivo class.\n",
    "8. Balanceo de clases# \n",
    "9. Aplicar SMOTE en el conjunto de entrenamiento para equilibrar clases.\n",
    "10. Entrenamiento de modelos# \n",
    "11. Probar múltiples algoritmos de clasificación:\n",
    "12. Regresión Logística, KNN, Naive Bayes, Árbol de Decisión, Random Forest y XGBoost.\n",
    "13. Evaluación de modelos# \n",
    "14. Calcular métricas (Accuracy, Recall, F1, ROC-AUC).\n",
    "15. Graficar matrices de confusión para comparar el desempeño.\n",
    "16. Validación cruzada# \n",
    "17. Comparar modelos con validación cruzada y LazyClassifier.\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913da53e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- 1. IMPORTACIÓN DE LIBRERÍAS ---\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# --- 2. CARGA Y EXPLORACIÓN DE DATOS ---\n",
    "print(\"\\n--- CARGA Y EXPLORACIÓN ---\")\n",
    "# Ruta al dataset\n",
    "data_path = r\"C:\\Users\\rportatil112\\Documents\\CURSO-DATA-SCIENCE\\EXAMEN\"\n",
    "os.chdir(data_path)\n",
    "df = pd.read_csv(\"all_datas_f.csv\")\n",
    "\n",
    "# ----- Información general\n",
    "\n",
    "df.shape # Dimensiones del dataset\n",
    "df.info()# Tipos de datos y estructura:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a409f75a",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "El dataset tiene 16 columnas y 522 filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14270a13",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Visualización de las primeras y últimas filas:\n",
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a812267",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "El data set contiene datos categóricos y numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7189f3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# ----- Análisis descriptivo\n",
    "\n",
    "df.describe() # Estadísticas para columnas numéricas:\n",
    "df.describe(include=['object'])# Estadísticas para columnas categóricas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dcbe34",
   "metadata": {
    "cell_marker": "'''",
    "lines_to_next_cell": 0
   },
   "source": [
    " Para las categóricas se observa que para estas tres columnas\n",
    "se destaca que efectivamente, body tiene valores nulos, y que hay un porcentaje alto de valores únicos,\n",
    "el método GET es más frecuente de los dos valores únicos que hay, y el valor más repetido es la petición /sendFeedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43f149e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# ----- Valores nulos y duplicados\n",
    "\n",
    "# Número y proporción de valores nulos por columna:\n",
    "df.isnull().sum()\n",
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e581edda",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    " Solo hay valores NaN en la columna de \"body\", concretamente el 80% de dicha columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04145ca1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df[df.isnull().any(axis=1)] # Filas con valores nulos:\n",
    "\n",
    "# Detección de filas duplicadas:\n",
    "df.duplicated().sum()\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0534427e",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "El valor de la duplicidad es por valores numéricos en los campos, no por filas o columnas\n",
    "se descarta que hayan filas o columnas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b4ddb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# ----- Análisis de columnas categóricas\n",
    "\n",
    "# Frecuencia de valores en cada columna categórica:\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    print(f\"Columna: {col}\")\n",
    "    print(df[col].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c742e526",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "- method: Hay más solicitudes GET que POST en este dataSet\n",
    "- path:Hay 228 rutas en total, las top 2 son /sendFeedback y /index.jsp?content=business_deposit.htm: , \n",
    "cabe la posibilidad de inyecciones de tráfico ya que algunas rutas tienen patrones sospechosos como java.lang.Thread.sleep, \n",
    "que podrían estar asociados con ataques \n",
    "- body: la cadena \"<?php exec('echo it6f7t1r2rx7ymxrs5fx',$colm);echo join(\"\\n\",$colm);die();?> aparece 16 veces y\n",
    "es bastante sospechosa, esta sospecha se basa en la ejecución de comandos PHP, inyecciones SQL,...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda78eb9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df.nunique() # Número de valores únicos por columna:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e721a52",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Podemos descartar las columnas: percentages y special_chars por ser poco relevantes\n",
    "   Binominalizamos las columnas c: path, body, path_length y body_lenght tienen los valores únicos más altos por lo que puede haber un patrón aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddf62a7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Matriz de correlación\n",
    "\n",
    "columns_num = df.select_dtypes(include=['number']).columns # Seleccionar columnas numéricas del DataFrame\n",
    "correlation_matrix = df[columns_num].corr() # Calcular la matriz de correlación\n",
    "print(\"\\n--- Matriz de correlación (solo numéricos) ---\")\n",
    "print(correlation_matrix.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f5a884",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    " Con respecto a nuestra variable objetivo (class), se observa a golpe de vista que para percentages y special_chart no aportan valor significativo, \n",
    "por lo que son susceptibles de eliminar, se procede a visualizar con un mapa de calor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc16597d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# CMapa de calor a partir de la matriz de correlación\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True, mask=correlation_matrix.isnull())\n",
    "plt.title(\"Matriz de Correlación (Solo Numéricos)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ab770",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    " El mapa de calor muestra relación con nuestra variable (class) objetivo con las siguientes variables: single_q, double_q, braces, spaces y badwords_count.\n",
    "Por otro lado, se observan fuertes-moderadas relaciones entre: single_q, spaces, braces, badwords_counts y dashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9432b5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# --- PREPARACIÓN DEL DATASET ---\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Eliminar columnas irrelevantes\n",
    "irrelevant_columns = [\"percentages\", \"special_chars\"]\n",
    "df = df.drop(columns=irrelevant_columns)\n",
    "\n",
    "df['body'] = df['body'].fillna(\"EMPTY\") # Imputar valores nulos en 'body' con \"EMPTY\"\n",
    "\n",
    "# Crear nuevas columnas basadas en palabras clave en 'path' y 'body'\n",
    "keywords = r'(java|sleep|exec|system)'\n",
    "df['path_keyword_count'] = df['path'].str.count(keywords)\n",
    "df['body_keyword_count'] = df['body'].str.count(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd919fe",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Crear nuevas columnas basadas en palabras clave:\n",
    "- El patrón de expresión regular (keywords) busca las palabras \"java\", \"sleep\", \"exec\" o \"system\".\n",
    "- Se utiliza el método .str.count() para contar cuántas veces aparecen estas palabras en cada fila.\n",
    "\n",
    "Nuevas columnas generadas:\n",
    "- 'path_keyword_count': Cantidad de palabras clave en la columna 'path'.\n",
    "- 'body_keyword_count': Cantidad de palabras clave en la columna 'body'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c485026",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['method'], drop_first=True) # Se convierte 'method' en variable binaria\n",
    "print(df.head()) # Verificar las transformaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dc2341",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Se han aplicado todas las transformaciones. En casos method o class nos vamos a asegurar\n",
    "mediante la técnica de SMOTE nos aseguraremos de equilibrar el peso para los valores minoritarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d6fd0b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "#Revisamos que no existen columnas categóricas antes de aplicar SMOTE\n",
    "columnas_categoricas = df.select_dtypes(include=['object']).columns\n",
    "print(\"Columnas categóricas restantes:\", columnas_categoricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e6cf4",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Aún nos quedan las columnas path y body como categóricas, además para path hay 228 valores únicos\n",
    "y para body 79 lo cual pueden ser datos muy representativos para el análisis por lo que procedemos\n",
    "a volver a discriminar en columnas por palabrar relevantes asociadas al tráfico sospechoso,\n",
    "buscamos en internt cuales son estas palabras asociadas a tráfico malicioso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44823bb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Extracción de palabras clave relacionadas con ataques y creación de columnas numéricas con la información recaudada\n",
    "# Lista de palabras clave sospechosas\n",
    "badwords = [\n",
    "    'sleep', 'uid', 'select', 'waitfor', 'delay', 'system', 'union', \n",
    "    'order by', 'group by', 'admin', 'drop', 'script', 'exec', \n",
    "    'ping', 'wget', 'curl', 'nslookup', 'net user', 'whoami', \n",
    "    'shutdown', 'reboot', '<script>', '</script>', '<iframe>', \n",
    "    '<img', 'onload=', 'javascript:', 'alert(', 'document.cookie', \n",
    "    'eval(', 'unescape(', '../', '..\\\\', '/etc/passwd', '/bin/bash', \n",
    "    'C:\\\\Windows\\\\System32', '(|)', '(&)', '!(|)', '*', '--', \n",
    "    'or 1=1', ';', 'debug', 'test', 'probe', 'exploit', 'malware', \n",
    "    'virus', 'attack', 'hacker', 'payload', 'shell', 'ftp', 'bash', \n",
    "    'powershell', 'chmod'\n",
    "]\n",
    "\n",
    "\n",
    "escaped_badwords = [re.escape(word) for word in badwords] # Escapar caracteres especiales en cada palabra clave\n",
    "badwords_pattern = r'|'.join(escaped_badwords) # Crear el patrón regex uniendo las palabras escapadas\n",
    "\n",
    "# Aplicar el patrón para contar palabras clave en las columnas 'path' y 'body'\n",
    "df['path_badwords_count'] = df['path'].str.count(badwords_pattern)\n",
    "df['body_badwords_count'] = df['body'].str.count(badwords_pattern)\n",
    "print(df[['path_badwords_count', 'body_badwords_count']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b10d1a",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Verificamos que efectivamente se han creado las columnas y que ha extraído valores númericos asociados\n",
    "a las palabras clave indicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816d8cb3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Se procede a eliminar estas dos columnas categóricas\n",
    "df = df.drop(columns=['body', 'path'])\n",
    "print(\"Columnas del dataset después de eliminar 'body' y 'path':\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036d7de3",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Verificamos que quedan borradas y nos aseguramos que el dataset es ya es \n",
    "completamente numérico y susceptible de ser entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe6834f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "correlation_matrix = df[['path_badwords_count', 'body_badwords_count', 'class']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlación con la clase objetivo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f3442",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Hay una correlación moderada con respecto a la variable objetivo \"class\", por lo que a priori podemos decir que la relación\n",
    "es positiva para el modelo y es útil, en principio vamos bien..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02de3b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "# Verificación de outliers\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns.tolist() # Seleccionar columnas numéricas actualizadas\n",
    "\n",
    "# Crear un gráfico de boxplot para cada columna\n",
    "plt.figure(figsize=(15, 10)) # Configurar tamaño de la figura y subplots\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    plt.subplot((len(numeric_cols) // 4) + 1, 4, i + 1)\n",
    "    sns.boxplot(y=df[col], color='skyblue')\n",
    "    plt.title(f\"Boxplot de {col}\")\n",
    "    plt.ylabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Distribución y Outliers en Columnas Numéricas\", fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f6e99",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Se observan muchos outliers en body_lenght y en path_lengt, lo cual es esperado y significativo para el modelo,\n",
    "se decide no hacer nada con ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a41463",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---> Verificar desbalanceo y aplicación de SMOTE en su caso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbbbb02",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Vamos a verificar si hay desbalanceo para evitar que los valores minoritarios no tengan peso para el modelo,\n",
    "en datos como este es importante ya que el trafico de virus suele ser minoritario con respecto al tráfico normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b8f474",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "class_counts = df['class'].value_counts() # Verificar el balance de clases en la columna objetivo\n",
    "print(\"Distribución de clases:\")\n",
    "print(class_counts)\n",
    "\n",
    "class_proportions = class_counts / len(df) # Proporción de clases\n",
    "print(\"\\nProporción de clases:\")\n",
    "print(class_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c830d1",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    " No está excesivamente desbalanceado pero al ser datos críticos de seguridad, aplicaremos para ajustar al máximo\n",
    "el balanceo y aplicaremos el SMOTE', importante aplicarlo en el test y no en el total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62ca5db",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Aplicación de SMOTE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separamos características (X) y la variable objetivo (y)\n",
    "X = df.drop(columns=['class'])  # Eliminar la columna objetivo\n",
    "y = df['class']  # Variable objetivo\n",
    "\n",
    "# Dividimos en conjunto de entrenamiento y prueba (opcional pero recomendado)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Aplicamos SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Verificamos balance de clases antes y después\n",
    "print(\"Distribución de clases antes de SMOTE:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nDistribución de clases después de SMOTE:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d41ab",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Mejora el balanceo en un 10% aproximado por lo que procedemos a seleccionar a probar con diferentes modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e7ae9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "# Exportamos el dataframe ya procesado para trabajar sobre él\n",
    "\n",
    "export_path = \"all_datas_f_preprocesado.csv\"  # Ruta donde se guardará el archivo\n",
    "df.to_csv(export_path, index=False)\n",
    "print(f\"Dataset preprocesado guardado en {export_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# ---> ENTRENAMIENTO Y EVALUACIÓN\n",
    "\n",
    "df = pd.read_csv(\"all_datas_f_preprocesado.csv\")\n",
    "print(\"Dataset cargado con éxito:\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Función para evaluar modelos y generar subplots\n",
    "def evaluar_modelos_en_ventana(modelos, X_train, y_train, X_test, y_test):\n",
    "    # Configurar subplots\n",
    "    num_modelos = len(modelos)\n",
    "    filas = (num_modelos // 2) + (num_modelos % 2)\n",
    "    fig, axes = plt.subplots(nrows=filas, ncols=2, figsize=(12, filas * 4))\n",
    "    axes = axes.flatten()  # Aplanar los ejes para iterar fácilmente\n",
    "    \n",
    "    for i, (nombre, modelo) in enumerate(modelos.items()):\n",
    "        print(f\"Entrenando y evaluando modelo: {nombre}\")\n",
    "        \n",
    "        # Entrenar el modelo\n",
    "        modelo.fit(X_train, y_train)\n",
    "        \n",
    "        # Hacer predicciones\n",
    "        predicciones = modelo.predict(X_test)\n",
    "        \n",
    "        # Calcular métricas\n",
    "        accuracy = accuracy_score(y_test, predicciones)\n",
    "        precision = precision_score(y_test, predicciones)\n",
    "        recall = recall_score(y_test, predicciones)\n",
    "        f1 = f1_score(y_test, predicciones)\n",
    "        roc_auc = roc_auc_score(y_test, modelo.predict_proba(X_test)[:, 1])\n",
    "        \n",
    "        # Mostrar métricas en consola\n",
    "        print(f\"\\n--- {nombre} ---\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "        \n",
    "        # Graficar la matriz de confusión\n",
    "        matriz_confusion = confusion_matrix(y_test, predicciones)\n",
    "        sns.heatmap(matriz_confusion, annot=True, fmt=\"d\", cmap=\"coolwarm\", ax=axes[i])\n",
    "        axes[i].set_title(f\"{nombre}\\nAccuracy: {accuracy:.2f}\")\n",
    "        axes[i].set_xlabel(\"Predicción\")\n",
    "        axes[i].set_ylabel(\"Real\")\n",
    "    \n",
    "    # Ocultar los ejes sobrantes si hay menos modelos que subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    # Ajustar diseño\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"Matriz de Confusión para Modelos\", fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Modelos a evaluar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "modelos = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=100, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"Bagging\": BaggingClassifier(random_state=42),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(random_state=42),\n",
    "    \"LGBM\": LGBMClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "# Llamada a la función\n",
    "evaluar_modelos_en_ventana(modelos, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abca888",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Random Forest se posiciona como el modelo más robusto al combinar un recall perfecto (100%) con un F1 Score y ROC-AUC \n",
    "sobresalientes, lo que lo hace ideal para aplicaciones donde evitar falsos negativos (tráfico malicioso no detectado) \n",
    "es crítico. Naive Bayes y Decision Tree también muestran un excelente rendimiento, siendo alternativas razonables si la \n",
    "eficiencia computacional o interpretabilidad son prioritarias.XGBoost y Logistic Regression son opciones equilibradas, con métricas sólidas y aplicables en escenarios menos críticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366c494b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- 6. VALIDACIÓN CRUZADA ---\n",
    "print(\"\\n--- VALIDACIÓN CRUZADA ---\")\n",
    "for nombre, modelo in modelos.items():\n",
    "    scores = cross_val_score(modelo, X, y, cv=5, scoring=\"accuracy\")\n",
    "    print(f\"{nombre} - Accuracy promedio: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c09fd",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "1. Naive Bayes obtuvo el mejor rendimiento promedio en validación cruzada (95.41%), mostrando su eficacia en este dataset.\n",
    "2. XGBoost y KNN también lograron altos desempeños con 94.63% y 94.07% respectivamente, siendo opciones sólidas.\n",
    "3. Logistic Regression y Random Forest tuvieron resultados aceptables (92.15% y 93.11%), aunque ligeramente por debajo de los mejores modelos.\n",
    "4. Decision Tree fue el modelo con menor rendimiento (91.01%), probablemente debido a su tendencia al sobreajuste en conjuntos pequeños."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c4910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 7. COMPARACIÓN CON LAZYCLASSIFIER ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecad7285",
   "metadata": {
    "cell_marker": "'''",
    "lines_to_next_cell": 0
   },
   "source": [
    "Tras haber jugado un poco con la librería Lazypredict, me resulta interesante terminar el análisis\n",
    "invocándola para comparar los resultados de los modelos estudiados con otros modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f8a4d9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- LAZYCLASSIFIER ---\")\n",
    "lazy_clf = LazyClassifier(verbose=0, ignore_warnings=True)\n",
    "models, predictions = lazy_clf.fit(X_train, X_test, y_train, y_test)\n",
    "print(models)\n",
    "\n",
    "# Visualizamos los resultados con un gráfico de barras\n",
    "plt.figure(figsize=(8, 8))  # Aumentamos el tamaño para mejor visibilidad\n",
    "sns.barplot(x=models.index, y=models[\"Accuracy\"], palette=\"viridis\")\n",
    "plt.title(\"Comparación de Modelos - LazyClassifier\", fontsize=16)\n",
    "plt.xlabel(\"Modelos\", fontsize=12)\n",
    "plt.ylabel(\"Precisión (Accuracy)\", fontsize=12)\n",
    "\n",
    "# Rotamos las etiquetas del eje X para mayor claridad\n",
    "plt.xticks(rotation=90, ha=\"center\", fontsize=10)\n",
    "\n",
    "# Mostramos el gráfico\n",
    "plt.tight_layout()  # Ajusta automáticamente los elementos para que no se superpongan\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582167f5",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Ninguno de los modelos supera en precisión a Ramdon Forest por lo que nos decantamos por este modelo en el presente análisis "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
